{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Text Classification"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loading sentences and labels\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "sentences = pd.read_csv(\"stanfordSentimentTreebank/datasetSentences.txt\", sep=\"\\t\")\n",
    "labels = pd.read_csv(\"stanfordSentimentTreebank/sentiment_labels.txt\", sep=\"|\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = sentences.merge(labels, left_on=\"sentence_index\", right_on=\"phrase ids\", how=\"left\")\n",
    "data = data[[\"sentence\", \"sentiment values\"]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment values</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>0.44444</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>0.50000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>0.42708</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>0.37500</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment values\n",
       "0  The Rock is destined to be the 21st Century 's...           0.50000\n",
       "1  The gorgeously elaborate continuation of `` Th...           0.44444\n",
       "2                     Effective but too-tepid biopic           0.50000\n",
       "3  If you sometimes like to go to the movies to h...           0.42708\n",
       "4  Emerges as something rare , an issue movie tha...           0.37500"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Converting Scores to labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [],
   "source": [
    "def map_sentiment(score):\n",
    "    if 0 <= score <= 0.2:\n",
    "        return 0  \n",
    "    elif 0.2 < score <= 0.4:\n",
    "        return 1\n",
    "    elif 0.4 < score <= 0.6:\n",
    "        return 2\n",
    "    elif 0.6 < score <= 0.8:\n",
    "        return 3\n",
    "    elif 0.8 < score <= 1.0:\n",
    "        return 4  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"label\"] = data[\"sentiment values\"].apply(map_sentiment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>sentence</th>\n",
       "      <th>sentiment values</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>The Rock is destined to be the 21st Century 's...</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>The gorgeously elaborate continuation of `` Th...</td>\n",
       "      <td>0.44444</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Effective but too-tepid biopic</td>\n",
       "      <td>0.50000</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you sometimes like to go to the movies to h...</td>\n",
       "      <td>0.42708</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Emerges as something rare , an issue movie tha...</td>\n",
       "      <td>0.37500</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            sentence  sentiment values  label\n",
       "0  The Rock is destined to be the 21st Century 's...           0.50000      2\n",
       "1  The gorgeously elaborate continuation of `` Th...           0.44444      2\n",
       "2                     Effective but too-tepid biopic           0.50000      2\n",
       "3  If you sometimes like to go to the movies to h...           0.42708      2\n",
       "4  Emerges as something rare , an issue movie tha...           0.37500      1"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Implemenation of Naiive Bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "class NaiveBayesClassifier:\n",
    "    def __init__(self, alpha=1.0):\n",
    "        \"\"\"\n",
    "        Initialize the Naive Bayes Classifier.\n",
    "        alpha: Smoothing parameter for Laplace smoothing.\n",
    "        \"\"\"\n",
    "        self.alpha = alpha  # Laplace smoothing\n",
    "        self.class_priors = None  # Prior probabilities P(Class)\n",
    "        self.word_probs = None  # Likelihood P(Word | Class)\n",
    "        self.vocab = None  # Vocabulary\n",
    "    \n",
    "    def fit(self, X, y):\n",
    "        \"\"\"\n",
    "        Train the classifier using text data.\n",
    "        X: List of text samples (sentences).\n",
    "        y: Corresponding class labels.\n",
    "        \"\"\"\n",
    "        # Create vocabulary\n",
    "        all_words = set(word for text in X for word in text.split())\n",
    "        self.vocab = {word: i for i, word in enumerate(all_words)}\n",
    "        V = len(self.vocab)  # Vocabulary size\n",
    "        \n",
    "        # Get unique class labels\n",
    "        classes = np.unique(y)\n",
    "        num_classes = len(classes)\n",
    "        \n",
    "        # Initialize probability tables\n",
    "        self.class_priors = np.zeros(num_classes)\n",
    "        word_counts = np.zeros((num_classes, V))  # Word frequency per class\n",
    "        class_counts = np.zeros(num_classes)  # Total words per class\n",
    "        \n",
    "        # Compute class priors and word counts\n",
    "        for i, cls in enumerate(classes):\n",
    "            class_indices = np.where(y == cls)[0]\n",
    "            self.class_priors[i] = len(class_indices) / len(y)  # P(Class)\n",
    "            \n",
    "            for idx in class_indices:\n",
    "                words = X[idx].split()\n",
    "                for word in words:\n",
    "                    if word in self.vocab:\n",
    "                        word_index = self.vocab[word]\n",
    "                        word_counts[i, word_index] += 1\n",
    "                        class_counts[i] += 1\n",
    "        \n",
    "        # Apply Laplace Smoothing: P(Word | Class) = (word_count + alpha) / (total_words + alpha * V)\n",
    "        self.word_probs = (word_counts + self.alpha) / (class_counts[:, None] + self.alpha * V)\n",
    "    \n",
    "    def predict(self, X):\n",
    "        \"\"\"\n",
    "        Predict the class of new text samples.\n",
    "        X: List of text samples (sentences).\n",
    "        \"\"\"\n",
    "        predictions = []\n",
    "        log_class_priors = np.log(self.class_priors)\n",
    "        \n",
    "        for text in X:\n",
    "            words = text.split()\n",
    "            log_probs = log_class_priors.copy()  # Initialize with log priors\n",
    "            \n",
    "            for word in words:\n",
    "                if word in self.vocab:\n",
    "                    word_index = self.vocab[word]\n",
    "                    log_probs += np.log(self.word_probs[:, word_index])\n",
    "            \n",
    "            predictions.append(np.argmax(log_probs))  # Choose class with highest log probability\n",
    "        \n",
    "        return np.array(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [],
   "source": [
    "shuffled_indices = np.random.permutation(len(data))  # Get shuffled indices\n",
    "data = data.iloc[shuffled_indices].reset_index(drop=True)  # Shuffle data\n",
    "train_size = int(0.8 * len(data))\n",
    "X_train, y_train = data[\"sentence\"][:train_size], np.array(data[\"label\"][:train_size])\n",
    "X_test, y_test = data[\"sentence\"][train_size:], np.array(data[\"label\"][train_size:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Test Accuracy: 0.5116\n",
      "Training samples: 9484, Test samples: 2371\n"
     ]
    }
   ],
   "source": [
    "nb = NaiveBayesClassifier()\n",
    "nb.fit(X_train, y_train)\n",
    "\n",
    "# Predict on test data\n",
    "y_pred = nb.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy = np.mean(y_pred == y_test)\n",
    "print(f\"Test Accuracy: {accuracy:.4f}\")\n",
    "print(f\"Training samples: {len(X_train)}, Test samples: {len(X_test)}\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Comparison with built in"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Scikit-Learn Naïve Bayes Accuracy: 0.5049\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.naive_bayes import MultinomialNB\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "# Create a pipeline with CountVectorizer + MultinomialNB\n",
    "model = make_pipeline(CountVectorizer(), MultinomialNB())\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train)\n",
    "\n",
    "# Predict using the trained model\n",
    "y_pred_sklearn = model.predict(X_test)\n",
    "\n",
    "# Evaluate accuracy\n",
    "accuracy_sklearn = accuracy_score(y_test, y_pred_sklearn)\n",
    "print(f\"Scikit-Learn Naïve Bayes Accuracy: {accuracy_sklearn:.4f}\")\n",
    "\n",
    " "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
